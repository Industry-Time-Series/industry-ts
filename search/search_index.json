{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Industry Time Series Library Time Series Manipulation for Industry Data This repository hosts the industry-ts : Indusstry Time Series Library --- a Python library that provides functions to manipulate time series collected from industrial contexts. This project aims to address the necessity for open-source tools developed for solving problems with data collected from industrial process. The modules introduced provide a variety of functions that are particularly tailored to industry data, directed to working with its most common issues, such as discontinuities in process measurements and faulty sensors. Table of Contents Main Features How to use it Documentation Main Features Data Generation : Generate synthetic data from well defined stochastic processes for testing and benchmarking purposes. Modelling : Fit time series models to data. Preprocessing : Preprocess time series with filtering, feature engineering and other techniques. How to use it To use the library, you can clone the repository and install it with pip: git clone https://github.com/Industry-Time-Series/industry-ts.git cd industry-ts pip install . Documentation The official documentation is hosted on https://industry-time-series.github.io/industry-ts/","title":"Home"},{"location":"#industry-time-series-library","text":"","title":"Industry Time Series Library"},{"location":"#time-series-manipulation-for-industry-data","text":"This repository hosts the industry-ts : Indusstry Time Series Library --- a Python library that provides functions to manipulate time series collected from industrial contexts. This project aims to address the necessity for open-source tools developed for solving problems with data collected from industrial process. The modules introduced provide a variety of functions that are particularly tailored to industry data, directed to working with its most common issues, such as discontinuities in process measurements and faulty sensors.","title":"Time Series Manipulation for Industry Data"},{"location":"#table-of-contents","text":"Main Features How to use it Documentation","title":"Table of Contents"},{"location":"#main-features","text":"Data Generation : Generate synthetic data from well defined stochastic processes for testing and benchmarking purposes. Modelling : Fit time series models to data. Preprocessing : Preprocess time series with filtering, feature engineering and other techniques.","title":"Main Features"},{"location":"#how-to-use-it","text":"To use the library, you can clone the repository and install it with pip: git clone https://github.com/Industry-Time-Series/industry-ts.git cd industry-ts pip install .","title":"How to use it"},{"location":"#documentation","text":"The official documentation is hosted on https://industry-time-series.github.io/industry-ts/","title":"Documentation"},{"location":"modules/industryts/generation/synthetic/","text":"ar_process source .ar_process( coefs: list, samples: int = 100, noise: float = 0 ) Generate synthetic data from an Autoregressive (AR) process of a given length and known coefficients, with the possibility of adding noise to the measurements. Args coefs (list) : list with coefficients of lagged measurements of samples (int) : number of data points to be generated. Default is 100. noise (float) : standard deviation of the noise to be added to the the series. The order of the AR process will be defined by the number of defined coefficients. For example, if coefs = [0.5, 0.3], the generated series will be an AR(2) process, where 0.5 is the coefficient of the first lagged measurement and 0.3 is the coefficient of the second lagged measurement. measurements. Default is 0, which means no noise. Returns series : array with the generated AR process. ma_process source .ma_process( coefs: list, samples: int = 100, noise: float = 0 ) Generate synthetic data from a Moving Average (MA) process of a given length and known coefficients, with the possibility of adding noise to the measurements. Args coefs (list) : list with coefficients of lagged measurements of samples (int) : number of data points to be generated. Default is 100. noise (float) : standard deviation of the noise to be added to the the series. The order of the MA process will be defined by the number of defined coefficients. For example, if coefs = [0.5, 0.3], the generated series will be an MA(2) process, where 0.5 is the coefficient of the first lagged measurement and 0.3 is the coefficient of the second lagged measurement. measurements. Default is 0, which means no noise. Returns series : array with the generated MA process. seasonal_component source .seasonal_component( samples: int = 100, period: int = 10, amplitude: float = 1, noise: float = 0 ) Generate a seasonal component of a given length, period and amplitude, with the possibility of adding noise to the measurements. The nature of the seasonal component is a sine wave with the given period and amplitude. Args samples (int) : number of data points to be generated. Default is 100. period (int) : period of the seasonal component. Default is 10. amplitude (float) : amplitude of the seasonal component. Default is 1. noise (float) : standard deviation of the noise to be added to the measurements. Default is 0, which means no noise. Returns series : array with the generated seasonal component. trend_component source .trend_component( samples: int = 100, slope: float = 0.1, intercept: float = 0, noise: float = 0 ) Generate a trend component of a given length, slope and intercept, with the possibility of adding noise to the measurements. Args samples (int) : number of data points to be generated. Default is 100. slope (float) : slope of the trend component. Default is 0. intercept (float) : intercept of the trend component. Default is 0. noise (float) : standard deviation of the noise to be added to the measurements. Default is 0, which means no noise. Returns series : array with the generated trend component. discontinuous_timeseries source .discontinuous_timeseries( start_timestamp: Union[str, pd.Timestamp], end_timestamp: Union[str, pd.Timestamp], freq: Union[str, pd.Timedelta], num_discontinuities: int, is_categorical: bool = False ) Generate a random discontinuous time series with given start and end timestamps and frequency. Args start_timestamp (str or Timestamp) : start date of the time series. end_timestamp (str or Timestamp) : end date of the time series. freq (str or Timedelta) : frequency of the time series. num_discontinuities (int) : number of discontinuity points to be is_categorical (bool) : if True, the time series will be categorical generated. with levels 'A', 'B', 'C' and 'D'. Default is False. Returns ts (Series) : discontinuous time series with random data. part_static_timeseries source .part_static_timeseries( start_timestamp: Union[str, pd.Timestamp], end_timestamp: Union[str, pd.Timestamp], frequency: Union[str, pd.Timedelta], n_samples_static: int, value_static: float = 1.0 ) Generate a time series with a part that is static. Args start_timestamp (Union[str, pd.Timestamp]) : Start date of the time end_timestamp (Union[str, pd.Timestamp]) : End date of the time series. n_samples_static (int) : Number of samples that will be static. series. Raises ValueError : Error raised if the number of samples is less than the number of static samples. Returns DataFrame : Time series with a part that is static.","title":"synthetic"},{"location":"modules/industryts/generation/synthetic/#_1","text":"","title":""},{"location":"modules/industryts/generation/synthetic/#ar_process","text":"source .ar_process( coefs: list, samples: int = 100, noise: float = 0 ) Generate synthetic data from an Autoregressive (AR) process of a given length and known coefficients, with the possibility of adding noise to the measurements. Args coefs (list) : list with coefficients of lagged measurements of samples (int) : number of data points to be generated. Default is 100. noise (float) : standard deviation of the noise to be added to the the series. The order of the AR process will be defined by the number of defined coefficients. For example, if coefs = [0.5, 0.3], the generated series will be an AR(2) process, where 0.5 is the coefficient of the first lagged measurement and 0.3 is the coefficient of the second lagged measurement. measurements. Default is 0, which means no noise. Returns series : array with the generated AR process.","title":"ar_process"},{"location":"modules/industryts/generation/synthetic/#ma_process","text":"source .ma_process( coefs: list, samples: int = 100, noise: float = 0 ) Generate synthetic data from a Moving Average (MA) process of a given length and known coefficients, with the possibility of adding noise to the measurements. Args coefs (list) : list with coefficients of lagged measurements of samples (int) : number of data points to be generated. Default is 100. noise (float) : standard deviation of the noise to be added to the the series. The order of the MA process will be defined by the number of defined coefficients. For example, if coefs = [0.5, 0.3], the generated series will be an MA(2) process, where 0.5 is the coefficient of the first lagged measurement and 0.3 is the coefficient of the second lagged measurement. measurements. Default is 0, which means no noise. Returns series : array with the generated MA process.","title":"ma_process"},{"location":"modules/industryts/generation/synthetic/#seasonal_component","text":"source .seasonal_component( samples: int = 100, period: int = 10, amplitude: float = 1, noise: float = 0 ) Generate a seasonal component of a given length, period and amplitude, with the possibility of adding noise to the measurements. The nature of the seasonal component is a sine wave with the given period and amplitude. Args samples (int) : number of data points to be generated. Default is 100. period (int) : period of the seasonal component. Default is 10. amplitude (float) : amplitude of the seasonal component. Default is 1. noise (float) : standard deviation of the noise to be added to the measurements. Default is 0, which means no noise. Returns series : array with the generated seasonal component.","title":"seasonal_component"},{"location":"modules/industryts/generation/synthetic/#trend_component","text":"source .trend_component( samples: int = 100, slope: float = 0.1, intercept: float = 0, noise: float = 0 ) Generate a trend component of a given length, slope and intercept, with the possibility of adding noise to the measurements. Args samples (int) : number of data points to be generated. Default is 100. slope (float) : slope of the trend component. Default is 0. intercept (float) : intercept of the trend component. Default is 0. noise (float) : standard deviation of the noise to be added to the measurements. Default is 0, which means no noise. Returns series : array with the generated trend component.","title":"trend_component"},{"location":"modules/industryts/generation/synthetic/#discontinuous_timeseries","text":"source .discontinuous_timeseries( start_timestamp: Union[str, pd.Timestamp], end_timestamp: Union[str, pd.Timestamp], freq: Union[str, pd.Timedelta], num_discontinuities: int, is_categorical: bool = False ) Generate a random discontinuous time series with given start and end timestamps and frequency. Args start_timestamp (str or Timestamp) : start date of the time series. end_timestamp (str or Timestamp) : end date of the time series. freq (str or Timedelta) : frequency of the time series. num_discontinuities (int) : number of discontinuity points to be is_categorical (bool) : if True, the time series will be categorical generated. with levels 'A', 'B', 'C' and 'D'. Default is False. Returns ts (Series) : discontinuous time series with random data.","title":"discontinuous_timeseries"},{"location":"modules/industryts/generation/synthetic/#part_static_timeseries","text":"source .part_static_timeseries( start_timestamp: Union[str, pd.Timestamp], end_timestamp: Union[str, pd.Timestamp], frequency: Union[str, pd.Timedelta], n_samples_static: int, value_static: float = 1.0 ) Generate a time series with a part that is static. Args start_timestamp (Union[str, pd.Timestamp]) : Start date of the time end_timestamp (Union[str, pd.Timestamp]) : End date of the time series. n_samples_static (int) : Number of samples that will be static. series. Raises ValueError : Error raised if the number of samples is less than the number of static samples. Returns DataFrame : Time series with a part that is static.","title":"part_static_timeseries"},{"location":"modules/industryts/models/univariate/","text":"UnivariateModel source UnivariateModel( order: int, family: str ) Base class for univariate models. Args order (int) : Order of the model. family (str) : Family of the model. Defaults to \"AR\". Attributes order : Order of the model. family : Family of the model. AutoRegressive source AutoRegressive( p: int = 1, bias: bool = True ) Class for purely autoregressive models of order p. Args p (int) : Order of the model. Defaults to 1. bias (bool) : Whether to include a bias term in the model. Defaults to True. Attributes p : Order of the model. coef : Coefficients of the model. Methods: .fit source .fit( data: Union[pd.DataFrame, np.ndarray] ) Fit the model to the data. .forecast source .forecast( initial_condition: Union[pd.DataFrame, np.ndarray], horizon: int = 1 ) Simulate the model forward in time. Args initial_conditions (ArrayLike) : Initial conditions for the model. horizon (int) : Number of steps to forecast. Defaults to 1. Returns forecast (ndarray) : Forecasted values. MovingAverage source MovingAverage( q: int = 1, bias: bool = True ) Class for purely moving average models of order q. Args q (int) : Order of the model. Defaults to 1. bias (bool) : Whether to include a bias term in the model. Defaults to True. Attributes q : Order of the model. coef : Coefficients of the model. Methods: .fit source .fit( data: Union[pd.DataFrame, np.ndarray], n_iterations: int = 100 ) Fit the model to the data.","title":"univariate"},{"location":"modules/industryts/models/univariate/#_1","text":"","title":""},{"location":"modules/industryts/models/univariate/#univariatemodel","text":"source UnivariateModel( order: int, family: str ) Base class for univariate models. Args order (int) : Order of the model. family (str) : Family of the model. Defaults to \"AR\". Attributes order : Order of the model. family : Family of the model.","title":"UnivariateModel"},{"location":"modules/industryts/models/univariate/#autoregressive","text":"source AutoRegressive( p: int = 1, bias: bool = True ) Class for purely autoregressive models of order p. Args p (int) : Order of the model. Defaults to 1. bias (bool) : Whether to include a bias term in the model. Defaults to True. Attributes p : Order of the model. coef : Coefficients of the model. Methods:","title":"AutoRegressive"},{"location":"modules/industryts/models/univariate/#fit","text":"source .fit( data: Union[pd.DataFrame, np.ndarray] ) Fit the model to the data.","title":".fit"},{"location":"modules/industryts/models/univariate/#forecast","text":"source .forecast( initial_condition: Union[pd.DataFrame, np.ndarray], horizon: int = 1 ) Simulate the model forward in time. Args initial_conditions (ArrayLike) : Initial conditions for the model. horizon (int) : Number of steps to forecast. Defaults to 1. Returns forecast (ndarray) : Forecasted values.","title":".forecast"},{"location":"modules/industryts/models/univariate/#movingaverage","text":"source MovingAverage( q: int = 1, bias: bool = True ) Class for purely moving average models of order q. Args q (int) : Order of the model. Defaults to 1. bias (bool) : Whether to include a bias term in the model. Defaults to True. Attributes q : Order of the model. coef : Coefficients of the model. Methods:","title":"MovingAverage"},{"location":"modules/industryts/models/univariate/#fit_1","text":"source .fit( data: Union[pd.DataFrame, np.ndarray], n_iterations: int = 100 ) Fit the model to the data.","title":".fit"},{"location":"modules/industryts/processing/featureengineering/","text":"counts_ratio_per_patch source .counts_ratio_per_patch( timeseries: pd.Series, patches_dicts: list, column: str, return_timestamps: bool = False ) Calculates the ratio between counts of all values in a patch of data Used for series with discrete inputs for data aggregation. This function expects a list of dictionaries with the start and end of every patch, in the same format as the output of the function industryts.processing.filtering.get_patches_dicts . Each item in the patches_dicts list is a dictionary with the following structure: { } The function returns a dataframe in which each column stores the ratio of a value in the column parameter in every patch. The column names follow the convention \"category_originalColName\". Args timeseries (pd.Series) : The time series to be processed patches_dicts (list) : The list containing the start and end of every data patch column (str) : The column name to be used in the ratio calculation return_timestamps (bool) : If True, the function will return the timestamps of the start and end of every patch. Defaults to False. Returns df_column_values (pd.DataFrame) : A dataframe contaning the ratio of column in every data window.","title":"featureengineering"},{"location":"modules/industryts/processing/featureengineering/#_1","text":"","title":""},{"location":"modules/industryts/processing/featureengineering/#counts_ratio_per_patch","text":"source .counts_ratio_per_patch( timeseries: pd.Series, patches_dicts: list, column: str, return_timestamps: bool = False ) Calculates the ratio between counts of all values in a patch of data Used for series with discrete inputs for data aggregation. This function expects a list of dictionaries with the start and end of every patch, in the same format as the output of the function industryts.processing.filtering.get_patches_dicts . Each item in the patches_dicts list is a dictionary with the following structure: { } The function returns a dataframe in which each column stores the ratio of a value in the column parameter in every patch. The column names follow the convention \"category_originalColName\". Args timeseries (pd.Series) : The time series to be processed patches_dicts (list) : The list containing the start and end of every data patch column (str) : The column name to be used in the ratio calculation return_timestamps (bool) : If True, the function will return the timestamps of the start and end of every patch. Defaults to False. Returns df_column_values (pd.DataFrame) : A dataframe contaning the ratio of column in every data window.","title":"counts_ratio_per_patch"},{"location":"modules/industryts/processing/filtering/","text":"get_continuous_patches source .get_continuous_patches( data: Union[pd.DataFrame, np.ndarray], sampling_time: pd.Timedelta = None, min_length: Union[str, int] = 0, drop_leading: int = 0, drop_trailing: int = 0, return_num_index: bool = False ) Function to extract the time limits for all continuous patches of data. In the context of industrial processes, each continuous patch may be associated with a batch, or simply a period of time where the process is continuously active between shutdowns. This function is often used in conjunction with a function for removivng samples in the data that were collected in periods of shutdown. Args data (pd.DataFrame) : The data to obtain the start and end timestamps. sampling_time (pd.Timedelta) : Sampling time. If None, it will be inferred from the data index. Defaults to None. min_length (str, int) : The minimum duration to consider a patch as drop_leading (int, optional) : Number of samples to drop from the start of each patch of data. Defaults to 0. drop_trailing (int, optional) : Number of samples to drop from the end of each patch of data. Defaults to 0. return_num_index (bool, optional) : If True, the function will return the row number of the start and end of each patch, instead of the timestamp index (if available). valid. If 'str', it must be a string that can be converted to a pd.Timedelta. If 'int', it must be an integer representing the number of samples. Defaults to 0, which means that all patches will be considered. Returns patches (list) : The list of dicts containing the start and end of each patch. rm_stopped_operation source .rm_stopped_operation( data: pd.DataFrame, rm_events_mask: np.ndarray, rm_interval_start: Union[str, pd.Timedelta] = '0S', rm_interval_stop: Union[str, pd.Timedelta] = '0S', minimum_interval: Union[str, pd.Timedelta] = '0S', return_shutdown_dict: bool = False ) Remove all samples in rm_events_mask, plus/minus stop_interval. Args data (pd.DataFrame) : data to be processed, must have datetime indexing rm_events_mask (ndarray) : boolean ndarray with length equal to number of rows in data, where rows to be removed are True rm_interval_start (Union[str, pd.Timedelta]) : time interval to be removed before the events in the mask rm_interval_stop (Union[str, pd.Timedelta]) : time interval to be removed after the events in the mask minimum_interval (string) : mininum duration of a stop return_shutdown_dict (bool) : if True, returns a dictionary with start and end indices of all events Returns DataFrame : data with the rows of rm_events_mask and samples around stop_interval removed, in addition to (optionally) shutdown dict. filter_static_windows source .filter_static_windows( data: pd.DataFrame, columns: list = None, threshold: int = 10, remove_window: bool = False, return_n_removed: bool = True ) Filter windows where there is no variation for 'threshold' consecutive samples. In other words, replace static windows for null values or remove windows, where a window is considered static if the value of the series remains unchanged for at least 'threshold' samples. Args data (pd.DataFrame) : Dataframe with the values to be analyzed columns (list, optional) : Columns to check if the windows are static. Defaults to []. threshold (int, optional) : Minimum length of sequence of samples with the same value to remove. Defaults to 10. remove_window (bool, optional) : If True, removes the static windows. If False, replace static windows with NA. Defaults to False. return_n_removed (bool, optional) : If True, returns the amount of removed samples for every column. Defaults to True. Returns DataFrame : Dataframe without the static windows (or NAs inplace). DataFrame : Columns with amount of static windows removed (or NAs inplace). remove_static_columns source .remove_static_columns( df: pd.DataFrame, min_std_cv: float = 0.01, columns: list = None, return_removed: bool = True ) Removes columns for which the coefficient of variation is below a selected threshold. If the mean of the column is 0, the standard deviation is used instead of the coefficient of variation. Args df (pd.DataFrame) : Process dataframe min_std_cv (float, optional) : Minimum variation coefficient. Defaults to 0.01. columns (list, optional) : List of columns to check. If None, all columns are checked. Defaults to None. return_removed (bool, optional) : If True, returns the removed columns and their coefficient of variation. Defaults to True. Returns DataFrame : The dataframe without the columns that don't change DataFrame : Dataframe with the columns that don't change and their coefficient of variation format_start source .format_start( df: pd.DataFrame, s: int = 0, m: int = 0, h: int = 0 ) Function to remove (if necessary) the first rows of the data in order to have the first row in a specific format. If the formatting is not possible, the function returns the original dataframe. Args df (pd.DataFrame) : df whose index is in datetime format. s (int) : initial second, with all windows starting with this second. m (int) : initial minute, with all windows starting with this minute. h (int) : if 0, initial hours are even; if 1, initial hours are odd. Returns DataFrame : with the specified format.","title":"filtering"},{"location":"modules/industryts/processing/filtering/#_1","text":"","title":""},{"location":"modules/industryts/processing/filtering/#get_continuous_patches","text":"source .get_continuous_patches( data: Union[pd.DataFrame, np.ndarray], sampling_time: pd.Timedelta = None, min_length: Union[str, int] = 0, drop_leading: int = 0, drop_trailing: int = 0, return_num_index: bool = False ) Function to extract the time limits for all continuous patches of data. In the context of industrial processes, each continuous patch may be associated with a batch, or simply a period of time where the process is continuously active between shutdowns. This function is often used in conjunction with a function for removivng samples in the data that were collected in periods of shutdown. Args data (pd.DataFrame) : The data to obtain the start and end timestamps. sampling_time (pd.Timedelta) : Sampling time. If None, it will be inferred from the data index. Defaults to None. min_length (str, int) : The minimum duration to consider a patch as drop_leading (int, optional) : Number of samples to drop from the start of each patch of data. Defaults to 0. drop_trailing (int, optional) : Number of samples to drop from the end of each patch of data. Defaults to 0. return_num_index (bool, optional) : If True, the function will return the row number of the start and end of each patch, instead of the timestamp index (if available). valid. If 'str', it must be a string that can be converted to a pd.Timedelta. If 'int', it must be an integer representing the number of samples. Defaults to 0, which means that all patches will be considered. Returns patches (list) : The list of dicts containing the start and end of each patch.","title":"get_continuous_patches"},{"location":"modules/industryts/processing/filtering/#rm_stopped_operation","text":"source .rm_stopped_operation( data: pd.DataFrame, rm_events_mask: np.ndarray, rm_interval_start: Union[str, pd.Timedelta] = '0S', rm_interval_stop: Union[str, pd.Timedelta] = '0S', minimum_interval: Union[str, pd.Timedelta] = '0S', return_shutdown_dict: bool = False ) Remove all samples in rm_events_mask, plus/minus stop_interval. Args data (pd.DataFrame) : data to be processed, must have datetime indexing rm_events_mask (ndarray) : boolean ndarray with length equal to number of rows in data, where rows to be removed are True rm_interval_start (Union[str, pd.Timedelta]) : time interval to be removed before the events in the mask rm_interval_stop (Union[str, pd.Timedelta]) : time interval to be removed after the events in the mask minimum_interval (string) : mininum duration of a stop return_shutdown_dict (bool) : if True, returns a dictionary with start and end indices of all events Returns DataFrame : data with the rows of rm_events_mask and samples around stop_interval removed, in addition to (optionally) shutdown dict.","title":"rm_stopped_operation"},{"location":"modules/industryts/processing/filtering/#filter_static_windows","text":"source .filter_static_windows( data: pd.DataFrame, columns: list = None, threshold: int = 10, remove_window: bool = False, return_n_removed: bool = True ) Filter windows where there is no variation for 'threshold' consecutive samples. In other words, replace static windows for null values or remove windows, where a window is considered static if the value of the series remains unchanged for at least 'threshold' samples. Args data (pd.DataFrame) : Dataframe with the values to be analyzed columns (list, optional) : Columns to check if the windows are static. Defaults to []. threshold (int, optional) : Minimum length of sequence of samples with the same value to remove. Defaults to 10. remove_window (bool, optional) : If True, removes the static windows. If False, replace static windows with NA. Defaults to False. return_n_removed (bool, optional) : If True, returns the amount of removed samples for every column. Defaults to True. Returns DataFrame : Dataframe without the static windows (or NAs inplace). DataFrame : Columns with amount of static windows removed (or NAs inplace).","title":"filter_static_windows"},{"location":"modules/industryts/processing/filtering/#remove_static_columns","text":"source .remove_static_columns( df: pd.DataFrame, min_std_cv: float = 0.01, columns: list = None, return_removed: bool = True ) Removes columns for which the coefficient of variation is below a selected threshold. If the mean of the column is 0, the standard deviation is used instead of the coefficient of variation. Args df (pd.DataFrame) : Process dataframe min_std_cv (float, optional) : Minimum variation coefficient. Defaults to 0.01. columns (list, optional) : List of columns to check. If None, all columns are checked. Defaults to None. return_removed (bool, optional) : If True, returns the removed columns and their coefficient of variation. Defaults to True. Returns DataFrame : The dataframe without the columns that don't change DataFrame : Dataframe with the columns that don't change and their coefficient of variation","title":"remove_static_columns"},{"location":"modules/industryts/processing/filtering/#format_start","text":"source .format_start( df: pd.DataFrame, s: int = 0, m: int = 0, h: int = 0 ) Function to remove (if necessary) the first rows of the data in order to have the first row in a specific format. If the formatting is not possible, the function returns the original dataframe. Args df (pd.DataFrame) : df whose index is in datetime format. s (int) : initial second, with all windows starting with this second. m (int) : initial minute, with all windows starting with this minute. h (int) : if 0, initial hours are even; if 1, initial hours are odd. Returns DataFrame : with the specified format.","title":"format_start"},{"location":"modules/industryts/processing/timestamps/","text":"infer_sampling_time source .infer_sampling_time( data: pd.DataFrame ) Infers sampling time from datetime index. If the index is not a datetime index, it will raise an error. Returns the sampling time as a pd.Timedelta object. The algorithm works by taking the first 10 samples and inferring the frequency from them. If the frequency is not inferred, it will take the next 10 samples and try again. This is repeated until the frequency is inferred or all samples are exhausted. Args data (pd.DataFrame) : Data frame with datetime index to infer the sampling time Returns t_s (pd.Timedelta) : The inferred sampling time","title":"timestamps"},{"location":"modules/industryts/processing/timestamps/#_1","text":"","title":""},{"location":"modules/industryts/processing/timestamps/#infer_sampling_time","text":"source .infer_sampling_time( data: pd.DataFrame ) Infers sampling time from datetime index. If the index is not a datetime index, it will raise an error. Returns the sampling time as a pd.Timedelta object. The algorithm works by taking the first 10 samples and inferring the frequency from them. If the frequency is not inferred, it will take the next 10 samples and try again. This is repeated until the frequency is inferred or all samples are exhausted. Args data (pd.DataFrame) : Data frame with datetime index to infer the sampling time Returns t_s (pd.Timedelta) : The inferred sampling time","title":"infer_sampling_time"}]}